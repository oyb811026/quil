import hashlib
import time
import aiohttp
import asyncio
import numpy as np
import os
import gc
from typing import Optional, Tuple
import concurrent.futures

class MemoryOptimizer:
    """å†…å­˜ä¼˜åŒ–ç®¡ç†å™¨"""
    def __init__(self, max_mem_mb=4096):
        self.max_mem = max_mem_mb * 1024 * 1024
        self.chunk_sizes = {
            500: 256,
            1000: 128,
            1500: 64,
            2000: 32
        }
    
    def get_chunk_size(self, matrix_size):
        """æ ¹æ®çŸ©é˜µå¤§å°åŠ¨æ€è°ƒæ•´åˆ†å—å¤§å°"""
        for size, chunk in sorted(self.chunk_sizes.items()):
            if matrix_size <= size:
                return chunk
        return 16  # é»˜è®¤æœ€å°åˆ†å—

    def memory_safe(self):
        """æ£€æŸ¥ç³»ç»Ÿå†…å­˜æ˜¯å¦å®‰å…¨"""
        try:
            import psutil
            avail = psutil.virtual_memory().available
            return avail > self.max_mem * 0.3  # ä¿ç•™30%ä½™é‡
        except:
            return True  # æ— psutilæ—¶é»˜è®¤å®‰å…¨

mem_optimizer = MemoryOptimizer()

def generate_matrix_chunked(seed: int, size: int) -> np.ndarray:
    """åˆ†å—ç”ŸæˆçŸ©é˜µé¿å…å†…å­˜å³°å€¼"""
    chunk_size = mem_optimizer.get_chunk_size(size)
    matrix = np.zeros((size, size), dtype=np.float32)  # ä½¿ç”¨float32èŠ‚çœå†…å­˜
    
    for i in range(0, size, chunk_size):
        for j in range(0, size, chunk_size):
            np.random.seed(seed + i + j)
            chunk = np.random.uniform(1, 1000, (chunk_size, chunk_size))
            matrix[i:i+chunk_size, j:j+chunk_size] = chunk
            del chunk
            gc.collect()
    
    return matrix

async def safe_matmul(a: np.ndarray, b: np.ndarray) -> np.ndarray:
    """å†…å­˜å®‰å…¨çš„çŸ©é˜µä¹˜æ³•"""
    size = a.shape[0]
    chunk_size = mem_optimizer.get_chunk_size(size)
    result = np.zeros((size, size), dtype=np.float32)
    
    for i in range(0, size, chunk_size):
        for j in range(0, size, chunk_size):
            for k in range(0, size, chunk_size):
                if not mem_optimizer.memory_safe():
                    await asyncio.sleep(0.1)
                    gc.collect()
                
                a_chunk = a[i:i+chunk_size, k:k+chunk_size]
                b_chunk = b[k:k+chunk_size, j:j+chunk_size]
                result[i:i+chunk_size, j:j+chunk_size] += np.dot(a_chunk, b_chunk)
                
                del a_chunk, b_chunk
                gc.collect()
    
    return result

async def compute_task(token: str, task_data: dict) -> Optional[Tuple[float, float]]:
    """å†…å­˜ä¼˜åŒ–çš„ä»»åŠ¡å¤„ç†"""
    seed1, seed2, size = task_data["seed1"], task_data["seed2"], task_data["matrix_size"]
    
    try:
        # é˜¶æ®µ1: ç”ŸæˆçŸ©é˜µ (åˆ†å—å¹¶è¡Œ)
        t0 = time.time() * 1000
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            a_future = executor.submit(generate_matrix_chunked, seed1, size)
            b_future = executor.submit(generate_matrix_chunked, seed2, size)
            A, B = await asyncio.gather(
                asyncio.wrap_future(a_future),
                asyncio.wrap_future(b_future)
            )
        
        # é˜¶æ®µ2: çŸ©é˜µä¹˜æ³• (åˆ†å—å¼‚æ­¥)
        C = await safe_matmul(A, B)
        
        # é˜¶æ®µ3: è®¡ç®—ç»“æœ
        flat_str = ''.join(f"{x:.0f}" for x in C.flat)
        sha256 = hashlib.sha256(flat_str.encode()).hexdigest()
        f = int(int(sha256, 16) % 10**7
        
        t1 = time.time() * 1000
        result_1 = t0 / max(f, 1)  # é¿å…é™¤é›¶
        result_2 = f / max((t1 - t0), 1)
        
        # ç«‹å³é‡Šæ”¾å†…å­˜
        del A, B, C, flat_str
        gc.collect()
        
        return result_1, result_2
        
    except Exception as e:
        print(f"[âŒ] è®¡ç®—å¤±è´¥ {token[:8]}: {str(e)}")
        return None

async def lightweight_worker(token: str):
    """å†…å­˜ä¼˜åŒ–çš„worker"""
    session = aiohttp.ClientSession()
    backoff = 1
    
    while True:
        try:
            # å†…å­˜æ£€æŸ¥
            if not mem_optimizer.memory_safe():
                print(f"[â³] {token[:8]} ç­‰å¾…å†…å­˜é‡Šæ”¾...")
                await asyncio.sleep(backoff)
                backoff = min(backoff * 2, 10)
                continue
                
            backoff = 1
            
            # è·å–ä»»åŠ¡
            headers = {"token": token}
            async with session.post(
                "https://nebulai.network/open_compute/finish/task",
                json={},
                headers=headers,
                timeout=10
            ) as resp:
                data = await resp.json()
                if data.get("code") != 0:
                    await asyncio.sleep(2)
                    continue
                    
                task_data = data['data']
                print(f"[ğŸ“¥] {token[:8]} è·å–{task_data['matrix_size']}é˜¶çŸ©é˜µä»»åŠ¡")
                
                # å¤„ç†ä»»åŠ¡
                results = await compute_task(token, task_data)
                if not results:
                    await asyncio.sleep(3)
                    continue
                    
                # æäº¤ç»“æœ
                payload = {
                    "result_1": f"{results[0]:.10f}",
                    "result_2": f"{results[1]:.10f}",
                    "task_id": task_data["task_id"]
                }
                async with session.post(
                    "https://nebulai.network/open_compute/finish/task",
                    json=payload,
                    headers=headers,
                    timeout=10
                ) as resp_submit:
                    submit_data = await resp_submit.json()
                    if submit_data.get("code") == 0:
                        print(f"[âœ…] {token[:8]} æäº¤æˆåŠŸ")
                        await asyncio.sleep(0.5)
                    else:
                        print(f"[âŒ] {token[:8]} æäº¤å¤±è´¥: {submit_data}")
                        await asyncio.sleep(2)
                        
        except Exception as e:
            print(f"[âš ï¸] {token[:8]} å‘ç”Ÿé”™è¯¯: {str(e)}")
            await asyncio.sleep(3)
        finally:
            gc.collect()

async def main():
    """å…¥å£å‡½æ•°"""
    if not os.path.exists("token.txt"):
        print("è¯·åˆ›å»ºtoken.txtæ–‡ä»¶å¹¶å¡«å…¥è®¿é—®ä»¤ç‰Œ")
        return
        
    with open("token.txt") as f:
        tokens = [line.strip() for line in f if line.strip()]
        
    if not tokens:
        print("token.txtä¸­æ²¡æœ‰æœ‰æ•ˆä»¤ç‰Œ")
        return
        
    # é™åˆ¶å¹¶å‘workeræ•°é‡
    semaphore = asyncio.Semaphore(min(4, len(tokens)))
    
    async def limited_worker(token):
        async with semaphore:
            await lightweight_worker(token)
    
    await asyncio.gather(*[limited_worker(token) for token in tokens])

if __name__ == "__main__":
    # é…ç½®NumPyå†…å­˜ç­–ç•¥
    os.environ["NPY_USE_CBLAS"] = "0"
    os.environ["OMP_NUM_THREADS"] = "1"
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n[ğŸ›‘] ç¨‹åºå·²åœæ­¢")
