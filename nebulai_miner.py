import hashlib, time, random, aiohttp, asyncio, numpy as np, os
import warnings
from typing import List, Optional, Tuple
import concurrent.futures

# å¿½ç•¥numpyçš„RuntimeWarningï¼Œé˜²æ­¢è­¦å‘Šä¿¡æ¯å¹²æ‰°è¾“å‡º
warnings.filterwarnings("ignore", category=RuntimeWarning, module="numpy")

def generate_matrix(seed: int, size: int) -> np.ndarray:
    """ç”ŸæˆæŒ‡å®šå¤§å°çš„çŸ©é˜µ
    Args:
        seed: éšæœºç§å­
        size: çŸ©é˜µå¤§å° (size x size)
    Returns:
        ç”Ÿæˆçš„çŸ©é˜µ
    """
    matrix = np.empty((size, size), dtype=np.float64)
    current_seed = seed
    # ä½¿ç”¨å›ºå®šç³»æ•°ç¡®ä¿çŸ©é˜µç”Ÿæˆçš„å¯é‡å¤æ€§
    a, b = 0x4b72e682d, 0x2675dcd22
    for i in range(size):
        for j in range(size):
            # ä½¿ç”¨çº¿æ€§åŒä½™ç®—æ³•ç”ŸæˆçŸ©é˜µå…ƒç´ å€¼
            value = (a * current_seed + b) % 1000
            matrix[i][j] = float(value)
            current_seed = value
    return matrix

def multiply_matrices(a: np.ndarray, b: np.ndarray) -> np.ndarray:
    """åˆ†å—çŸ©é˜µä¹˜æ³•é¿å…æ•°å€¼æº¢å‡ºé—®é¢˜
    Args:
        a: ç¬¬ä¸€ä¸ªçŸ©é˜µ
        b: ç¬¬äºŒä¸ªçŸ©é˜µ
    Returns:
        çŸ©é˜µä¹˜ç§¯ç»“æœ
    """
    n = a.shape[0]
    chunk_size = 512  # åˆ†å—å¤§å°ï¼Œæ ¹æ®å†…å­˜è°ƒæ•´ï¼ˆMac M4å»ºè®®512ï¼‰
    c = np.zeros((n, n), dtype=np.float64)  # ç»“æœçŸ©é˜µ
    
    # ä¸‰é‡å¾ªç¯å®ç°åˆ†å—çŸ©é˜µä¹˜æ³•
    for i in range(0, n, chunk_size):
        for j in range(0, n, chunk_size):
            for k in range(0, n, chunk_size):
                # è®¡ç®—å½“å‰å—çš„ç»“æŸä½ç½®
                i_end = min(i + chunk_size, n)
                j_end = min(j + chunk_size, n)
                k_end = min(k + chunk_size, n)
                
                # æå–å½“å‰å­çŸ©é˜µå—
                a_block = a[i:i_end, k:k_end]
                b_block = b[k:k_end, j:j_end]
                
                # è®¡ç®—å­çŸ©é˜µä¹˜ç§¯å¹¶ç´¯åŠ åˆ°ç»“æœçŸ©é˜µ
                c[i:i_end, j:j_end] += np.dot(a_block, b_block)
    return c

def flatten_matrix(matrix: np.ndarray) -> str:
    """å°†çŸ©é˜µæ‰å¹³åŒ–ä¸ºå­—ç¬¦ä¸²
    Args:
        matrix: è¾“å…¥çŸ©é˜µ
    Returns:
        æ‰å¹³åŒ–åçš„å­—ç¬¦ä¸²è¡¨ç¤º
    """
    return ''.join(f"{x:.0f}" for x in matrix.flat)

async def compute_hash_mod(matrix: np.ndarray, mod: int = 10**7) -> int:
    """è®¡ç®—çŸ©é˜µçš„SHA256å“ˆå¸Œæ¨¡å€¼
    Args:
        matrix: è¾“å…¥çŸ©é˜µ
        mod: æ¨¡æ•° (é»˜è®¤10^7)
    Returns:
        å“ˆå¸Œæ¨¡å€¼
    """
    flat_str = flatten_matrix(matrix)
    sha256 = hashlib.sha256(flat_str.encode()).hexdigest()
    return int(int(sha256, 16) % mod)

async def fetch_task(session: aiohttp.ClientSession, token: str) -> Tuple[dict, bool]:
    """ä»æœåŠ¡å™¨è·å–è®¡ç®—ä»»åŠ¡
    Args:
        session: aiohttpä¼šè¯å¯¹è±¡
        token: ç”¨æˆ·è®¤è¯ä»¤ç‰Œ
    Returns:
        (ä»»åŠ¡æ•°æ®, æ˜¯å¦æˆåŠŸ)
    """
    headers = {"Content-Type": "application/json", "token": token}
    try:
        async with session.post("https://nebulai.network/open_compute/finish/task", 
                                json={}, headers=headers, timeout=10) as resp:
            data = await resp.json()
            if data.get("code") == 0:
                print(f"[ğŸ“¥] ä»»åŠ¡è·å–æˆåŠŸ {token[:8]} (çŸ©é˜µå¤§å°: {data['data']['matrix_size']})")
                return data['data'], True
            return None, False
    except Exception as e:
        print(f"[âš ï¸] ä»»åŠ¡è·å–å¤±è´¥ {token[:8]}: {str(e)}")
        return None, False

async def submit_results(session: aiohttp.ClientSession, token: str, 
                         r1: float, r2: float, task_id: str) -> bool:
    """å‘æœåŠ¡å™¨æäº¤è®¡ç®—ç»“æœ
    Args:
        session: aiohttpä¼šè¯å¯¹è±¡
        token: ç”¨æˆ·è®¤è¯ä»¤ç‰Œ
        r1: è®¡ç®—ç»“æœ1
        r2: è®¡ç®—ç»“æœ2
        task_id: ä»»åŠ¡ID
    Returns:
        æäº¤æ˜¯å¦æˆåŠŸ
    """
    headers = {"Content-Type": "application/json", "token": token}
    payload = {
        "result_1": f"{r1:.10f}", 
        "result_2": f"{r2:.10f}", 
        "task_id": task_id
    }
    try:
        async with session.post("https://nebulai.network/open_compute/finish/task", 
                                json=payload, headers=headers, timeout=10) as resp:
            data = await resp.json()
            if data.get("code") == 0 and data.get("data", {}).get("calc_status", False):
                print(f"[âœ…] ç»“æœæäº¤æˆåŠŸ {token[:8]}")
                return True
            print(f"[âŒ] ç»“æœè¢«æ‹’ç» {token[:8]}: {data}")
            return False
    except Exception as e:
        print(f"[âš ï¸] æäº¤å¤±è´¥ {token[:8]}: {str(e)}")
        return False

async def process_task(token: str, task_data: dict) -> Optional[Tuple[float, float]]:
    """å¤„ç†å•ä¸ªè®¡ç®—ä»»åŠ¡
    Args:
        token: ç”¨æˆ·è®¤è¯ä»¤ç‰Œ
        task_data: ä»»åŠ¡æ•°æ®
    Returns:
        (è®¡ç®—ç»“æœ1, è®¡ç®—ç»“æœ2) æˆ– Noneï¼ˆå¤„ç†å¤±è´¥æ—¶ï¼‰
    """
    seed1, seed2, size = task_data["seed1"], task_data["seed2"], task_data["matrix_size"]
    try:
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œç”Ÿæˆä¸¤ä¸ªçŸ©é˜µ
        with concurrent.futures.ThreadPoolExecutor() as executor:
            t0 = time.time() * 1000  # è®°å½•å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
            A_future = executor.submit(generate_matrix, seed1, size)
            B_future = executor.submit(generate_matrix, seed2, size)
            A, B = await asyncio.gather(
                asyncio.wrap_future(A_future),
                asyncio.wrap_future(B_future)
            )
        
        # è®¡ç®—çŸ©é˜µä¹˜ç§¯å’Œå“ˆå¸Œ
        C = multiply_matrices(A, B)
        f = await compute_hash_mod(C)
        t1 = time.time() * 1000  # è®°å½•ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        
        # é¿å…é™¤é›¶é”™è¯¯
        time_diff = t1 - t0
        if time_diff == 0:
            time_diff = 1e-9  # å¾®å°å€¼é¿å…é™¤é›¶
        
        # è®¡ç®—æœ€ç»ˆç»“æœ
        result_1 = t0 / f
        result_2 = f / time_diff
        
        return result_1, result_2
    except Exception as e:
        print(f"[âŒ] è®¡ç®—é”™è¯¯: {str(e)}")
        return None

async def worker_loop(token: str):
    """å•ä¸ªtokençš„å·¥ä½œå¾ªç¯
    Args:
        token: ç”¨æˆ·è®¤è¯ä»¤ç‰Œ
    """
    async with aiohttp.ClientSession() as session:
        while True:
            # 1. è·å–ä»»åŠ¡
            task_data, success = await fetch_task(session, token)
            if not success:
                await asyncio.sleep(2)  # å¤±è´¥åçŸ­æš‚ç­‰å¾…é‡è¯•
                continue
            
            # 2. å¤„ç†ä»»åŠ¡
            results = await process_task(token, task_data)
            if not results:
                await asyncio.sleep(1)  # è®¡ç®—å¤±è´¥åçŸ­æš‚ç­‰å¾…
                continue
            
            # 3. æäº¤ç»“æœ
            submitted = await submit_results(
                session, token, results[0], results[1], task_data["task_id"])
            
            # æ ¹æ®æäº¤ç»“æœè°ƒæ•´ç­‰å¾…æ—¶é—´
            await asyncio.sleep(0.5 if submitted else 3)

async def main():
    """ä¸»å‡½æ•°ï¼šå¯åŠ¨æ‰€æœ‰å·¥ä½œå¾ªç¯"""
    # æ£€æŸ¥tokenæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists("token.txt"):
        print("æœªæ‰¾åˆ°token.txtæ–‡ä»¶!")
        return
    
    # è¯»å–æ‰€æœ‰token
    with open("token.txt") as f:
        tokens = [line.strip() for line in f if line.strip()]
    
    if not tokens:
        print("token.txtä¸­æ²¡æœ‰æœ‰æ•ˆçš„token!")
        return
    
    # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘ä»»åŠ¡æ•°ï¼ˆé˜²æ­¢å†…å­˜æº¢å‡ºï¼‰
    semaphore = asyncio.Semaphore(4)  # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´ï¼ˆMac M4å»ºè®®4-8ï¼‰
    
    async def limited_worker(token):
        """å¸¦å¹¶å‘é™åˆ¶çš„å·¥ä½œå‡½æ•°"""
        async with semaphore:
            await worker_loop(token)
    
    # å¯åŠ¨æ‰€æœ‰å·¥ä½œå¾ªç¯
    await asyncio.gather(*(limited_worker(token) for token in tokens))

if __name__ == "__main__":
    try:
        # å¯åŠ¨ä¸»å¼‚æ­¥å¾ªç¯
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n[â›”] ç”¨æˆ·ä¸­æ–­ç¨‹åº")
